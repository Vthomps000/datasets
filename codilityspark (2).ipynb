{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "pip install pyspark"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GwsP35gsUNg6",
        "outputId": "095da41c-3c96-4231-ec87-bfa4ecdc6ef8"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pyspark\n",
            "  Downloading pyspark-3.4.1.tar.gz (310.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m310.8/310.8 MB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: py4j==0.10.9.7 in /usr/local/lib/python3.10/dist-packages (from pyspark) (0.10.9.7)\n",
            "Building wheels for collected packages: pyspark\n",
            "  Building wheel for pyspark (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyspark: filename=pyspark-3.4.1-py2.py3-none-any.whl size=311285398 sha256=84f93c33742b79226598e2d35f1d6fc488d9a741d7e4a4d6d4da2cb86a37a0d1\n",
            "  Stored in directory: /root/.cache/pip/wheels/0d/77/a3/ff2f74cc9ab41f8f594dabf0579c2a7c6de920d584206e0834\n",
            "Successfully built pyspark\n",
            "Installing collected packages: pyspark\n",
            "Successfully installed pyspark-3.4.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "O3ksMv2JUPXL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "AmJsNC8FUPZ9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "w0hdFINMUPcX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "F2FyM3j2UPe5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "7tLAy1M7UNkx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "Tg9oc3LWUAxe"
      },
      "outputs": [],
      "source": [
        "\n",
        "from pyspark.sql import SparkSession\n",
        "from pyspark.sql.types import StringType,IntegerType,StructType,StructField,FloatType\n",
        "from pyspark.sql.functions import when, col, udf"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "spark = SparkSession.builder.appName(\"exp\").getOrCreate()\n",
        "sc = spark.sparkContext"
      ],
      "metadata": {
        "id": "1cNgWLE7Ug6a"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sc = spark.sparkContext"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 165
        },
        "id": "cBhUvCJAOlFv",
        "outputId": "83dfbe6d-f58d-48fc-e51b-af67f9c1844a"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-11-ed5a16d870c0>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0msc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mspark\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msparkContext\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'spark' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "lY-EVwYIOlPJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_english_name(species):\n",
        "return species.split('(')[0].rstrip()\n",
        "def get_start_year(period):\n",
        "return int(period.split(\"-\")[0][1:])\n",
        "def get_trend(annual_percentage_change):\n",
        "if annual_percentage_change <= -3.00:\n",
        "return 'strong decline'\n",
        "elif annual_percentage_change > -3.00 and annual_percentage_change <= -0.50:\n",
        "return 'weak decline'\n",
        "elif annual_percentage_change > -0.50 and annual_percentage_change < 0.50:\n",
        "return 'no change'\n",
        "elif annual_percentage_change >= 0.50 and annual_percentage_change <= 3.00:\n",
        "return 'weak increase'\n",
        "elif annual_percentage_change > 3.00:\n",
        "return 'strong increase'"
      ],
      "metadata": {
        "id": "XB3ELYy5OlUL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "aCIl-ftnOlW7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "kskPX357OlZX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "@udf(returnType=StringType())\n",
        "def get_english_name(val):\n",
        "    return val[0:val.index(\" (\")]\n",
        "\n",
        "@udf(returnType=IntegerType())\n",
        "def get_start_year(val):\n",
        "    return int(val[1:5])\n",
        "\n",
        "@udf(returnType=StringType())\n",
        "def get_trend(x):\n",
        "    if x < -3.00:\n",
        "        return \"strong decline\"\n",
        "    elif -3.00 < x < -0.50:\n",
        "        return \"weak decline\"\n",
        "    elif -0.50 <x<0.50:\n",
        "        return \"no change\"\n",
        "    else:\n",
        "        return \"strong increase\""
      ],
      "metadata": {
        "id": "aayvG9X8Ug-C"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "s2vWzOZARwpu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "8n9tMxb-Rws2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Register UDF\n",
        "\n",
        "get_english_nameUDF = udf(get_english_name,StringType())\n",
        "get_start_yearUDF = udf(get_start_year,IntegerType())\n",
        "get_trendUDF = udf(get_trend,StringType())\n"
      ],
      "metadata": {
        "id": "e_fgzJvdLexV"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "spark.udf.register(\"_nullsafeUDF\", lambda str: convertCase(str) if not str is None else \"\" , StringType())"
      ],
      "metadata": {
        "id": "SFwPNNhzR2Fa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "tD4JKGQHR2Oi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = df.withColumn(\"Species\", get_english_name(df.Species)).withColumn(\"Period\",\n",
        "get_start_year(df.Period)).withColumn(\"trend\", get_trend(col(\"Annual percentage\n",
        "change\"))).withColumnRenamed(\"Species\", \"species\").withColumnRenamed(\"Category\",\n",
        "\"category\").withColumnRenamed(\"Period\",\n",
        "\"collected_from_year\").withColumnRenamed(\"Annual percentage change\",\n",
        "\"annual_percentage_change\")\n",
        "return df\n"
      ],
      "metadata": {
        "id": "t3XlPnPALe5e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "KATBWVzsLe8L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.show(10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 165
        },
        "id": "yfelOTb5Le-w",
        "outputId": "1a1b3a15-17e1-47a2-e906-fea6a8f62590"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-4-f69586b927dc>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m: 'list' object has no attribute 'show'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = [(\"Greenfinch (Chloris chloris)\",\"Farmland birds\",\"(1970-2014)\",-1.13),(\"Siskin (Carduelis spinus)\",\"Woodland birds\",\"(1995-2014)\",2.26),\n",
        "        (\"European shag (Phalacrocorax artistotelis)\",\"Seabirds\",\"(1986-2014)\",-2.31),(\"Mute Swan (Cygnus olor)\",\"Water and wetland birds\",\"(1975-2014)\",1.65)\n",
        "        ,(\"Collared Dove (Streptopelia decaocto)\",\"other\",\"(1970-2014)\",5.2)]"
      ],
      "metadata": {
        "id": "_BHgoSshLfCU"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "kl9R1k3nLfEx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "info = [(\"Greenfinch (Chloris chloris)\",\"Farmland birds\",\"(1970-2014)\",-1.13),(\"Siskin (Carduelis spinus)\",\"Woodland birds\",\"(1995-2014)\",2.26),\n",
        "        (\"European shag (Phalacrocorax artistotelis)\",\"Seabirds\",\"(1986-2014)\",-2.31),(\"Mute Swan (Cygnus olor)\",\"Water and wetland birds\",\"(1975-2014)\",1.65)\n",
        "        ,(\"Collared Dove (Streptopelia decaocto)\",\"other\",\"(1970-2014)\",5.2)]\n",
        "schema1 = StructType(\n",
        "    [StructField(\"Species\", StringType()),\n",
        "     StructField(\"Category\", StringType()),\n",
        "     StructField(\"Period\", StringType()),\n",
        "     StructField(\"Annual_percentage_change\", FloatType())\n",
        "     ])"
      ],
      "metadata": {
        "id": "Ws0EuIREUhAh"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rdd = sc.parallelize(info)\n",
        "data = spark.createDataFrame(rdd, schema=schema1)"
      ],
      "metadata": {
        "id": "PyPial7uUhC7"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Decorator\n",
        "\n",
        "data2 = data.withColumn(\"English_Name\", get_english_nameUDF(col(\"Species\")))\\\n",
        "    .withColumn(\"start_yearn\", get_start_yearUDF(col(\"Period\")))\\\n",
        "        .withColumn(\"Trend\", get_trendUDF(col(\"Annual_percentage_change\")))\n"
      ],
      "metadata": {
        "id": "AAp59fX8U_sE"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data2.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 467
        },
        "id": "FjpkMROvSIg4",
        "outputId": "cc1f64eb-2665-4766-b824-a4acd17baf48"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "error",
          "ename": "PythonException",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mPythonException\u001b[0m                           Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-18-ae090e13f854>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdata2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pyspark/sql/dataframe.py\u001b[0m in \u001b[0;36mshow\u001b[0;34m(self, n, truncate, vertical)\u001b[0m\n\u001b[1;32m    897\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    898\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtruncate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbool\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mtruncate\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 899\u001b[0;31m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshowString\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvertical\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    900\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    901\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/py4j/java_gateway.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1320\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1321\u001b[0m         \u001b[0manswer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgateway_client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_command\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1322\u001b[0;31m         return_value = get_return_value(\n\u001b[0m\u001b[1;32m   1323\u001b[0m             answer, self.gateway_client, self.target_id, self.name)\n\u001b[1;32m   1324\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pyspark/errors/exceptions/captured.py\u001b[0m in \u001b[0;36mdeco\u001b[0;34m(*a, **kw)\u001b[0m\n\u001b[1;32m    173\u001b[0m                 \u001b[0;31m# Hide where the exception came from that shows a non-Pythonic\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    174\u001b[0m                 \u001b[0;31m# JVM exception message.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 175\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mconverted\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    176\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    177\u001b[0m                 \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mPythonException\u001b[0m: \n  An exception was thrown from the Python worker. Please see the stack trace below.\nTraceback (most recent call last):\n  File \"/usr/local/lib/python3.10/dist-packages/pyspark/sql/udf.py\", line 421, in wrapper\n    return self(*args)\n  File \"/usr/local/lib/python3.10/dist-packages/pyspark/python/lib/pyspark.zip/pyspark/sql/udf.py\", line 338, in __call__\n    sc = get_active_spark_context()\n  File \"/usr/local/lib/python3.10/dist-packages/pyspark/python/lib/pyspark.zip/pyspark/sql/utils.py\", line 202, in get_active_spark_context\n    raise RuntimeError(\"SparkContext or SparkSession should be created first.\")\nRuntimeError: SparkContext or SparkSession should be created first.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ec_aUjYeU_uF",
        "outputId": "7d6033fa-f106-40b4-9774-4847a8160663"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------------+--------------------+-----------+------------------------+\n",
            "|             Species|            Category|     Period|Annual_percentage_change|\n",
            "+--------------------+--------------------+-----------+------------------------+\n",
            "|Greenfinch (Chlor...|      Farmland birds|(1970-2014)|                   -1.13|\n",
            "|Siskin (Carduelis...|      Woodland birds|(1995-2014)|                    2.26|\n",
            "|European shag (Ph...|            Seabirds|(1986-2014)|                   -2.31|\n",
            "|Mute Swan (Cygnus...|Water and wetland...|(1975-2014)|                    1.65|\n",
            "|Collared Dove (St...|               other|(1970-2014)|                     5.2|\n",
            "+--------------------+--------------------+-----------+------------------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data.printSchema()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7UqqY56tTfI0",
        "outputId": "00ec4fd5-8784-4b4f-84b7-5ab36cfbeb65"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- Species: string (nullable = true)\n",
            " |-- Category: string (nullable = true)\n",
            " |-- Period: string (nullable = true)\n",
            " |-- Annual_percentage_change: float (nullable = true)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "spark.stop()"
      ],
      "metadata": {
        "id": "XzMiuPcTU_wk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "hh12GWHXU_y7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "V5uFg3hbU_37"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "rBlcnAsRUhJS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import findspark\n",
        "findspark.init()\n",
        "from pyspark.sql import SparkSession\n",
        "from pyspark.sql.types import StringType,IntegerType,StructType,StructField,FloatType\n",
        "from pyspark.sql.functions import when, col, udf\n",
        "spark = SparkSession.builder.appName(\"exp\").getOrCreate()\n",
        "sc = spark.sparkContext\n",
        "@udf(returnType=StringType())\n",
        "def get_english_name(val):\n",
        "    return val[0:val.index(\" (\")]\n",
        "\n",
        "@udf(returnType=IntegerType())\n",
        "def get_start_year(val):\n",
        "    return int(val[1:5])\n",
        "\n",
        "@udf(returnType=StringType())\n",
        "def get_trend(x):\n",
        "    if x < -3.00:\n",
        "        return \"strong decline\"\n",
        "    elif -3.00 < x < -0.50:\n",
        "        return \"weak decline\"\n",
        "    elif -0.50 <x<0.50:\n",
        "        return \"no change\"\n",
        "    else:\n",
        "        return \"strong increase\"\n",
        "\n",
        "info = [(\"Greenfinch (Chloris chloris)\",\"Farmland birds\",\"(1970-2014)\",-1.13),(\"Siskin (Carduelis spinus)\",\"Woodland birds\",\"(1995-2014)\",2.26),\n",
        "        (\"European shag (Phalacrocorax artistotelis)\",\"Seabirds\",\"(1986-2014)\",-2.31),(\"Mute Swan (Cygnus olor)\",\"Water and wetland birds\",\"(1975-2014)\",1.65)\n",
        "        ,(\"Collared Dove (Streptopelia decaocto)\",\"other\",\"(1970-2014)\",5.2)]\n",
        "schema1 = StructType(\n",
        "    [StructField(\"Species\", StringType()),\n",
        "     StructField(\"Category\", StringType()),\n",
        "     StructField(\"Period\", StringType()),\n",
        "     StructField(\"Annual_percentage_change\", FloatType())\n",
        "     ])\n",
        "\n",
        "rdd = sc.parallelize(info)\n",
        "data = spark.createDataFrame(rdd, schema=schema1)\n",
        "\n",
        "data2 = data.withColumn(\"English_Name\", get_english_name(col(\"Species\")))\\\n",
        "    .withColumn(\"start_yearn\", get_start_year(col(\"Period\")))\\\n",
        "        .withColumn(\"Trend\", get_trend(col(\"Annual_percentage_change\")))\n",
        "data2.show()\n",
        "spark.stop()"
      ],
      "metadata": {
        "id": "QlG9SySsUBfJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "F--fUcqXUBhw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "7QmdTggCUBkv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Qe4CJ9vPUBm8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "4nSYLnlMUBo_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "GTMMLzY-UBtn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.functions import *\n",
        "from pyspark.sql.types import *\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "AmjrgjpaUBwY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_english_name(species):\n",
        "return species.split('(')[0].rstrip()\n",
        "def get_start_year(period):\n",
        "return int(period.split(\"-\")[0][1:])\n",
        "def get_trend(annual_percentage_change):\n",
        "if annual_percentage_change <= -3.00:\n",
        "return 'strong decline'\n",
        "elif annual_percentage_change > -3.00 and annual_percentage_change <= -0.50:\n",
        "return 'weak decline'\n",
        "elif annual_percentage_change > -0.50 and annual_percentage_change < 0.50:\n",
        "return 'no change'\n",
        "elif annual_percentage_change >= 0.50 and annual_percentage_change <= 3.00:\n",
        "return 'weak increase'\n",
        "elif annual_percentage_change > 3.00:\n",
        "return 'strong increase'"
      ],
      "metadata": {
        "id": "VkDWn5iVO5Na"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "get_english_name = udf(get_english_name,StringType())\n",
        "get_start_year = udf(get_start_year,IntegerType())\n",
        "get_trend = udf(get_trend,StringType())"
      ],
      "metadata": {
        "id": "yXDzvwbqO5QH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = df.withColumn(\"Species\", get_english_name(df.Species)).withColumn(\"Period\",\n",
        "get_start_year(df.Period)).withColumn(\"trend\", get_trend(col(\"Annual percentage\n",
        "change\"))).withColumnRenamed(\"Species\", \"species\").withColumnRenamed(\"Category\",\n",
        "\"category\").withColumnRenamed(\"Period\",\n",
        "\"collected_from_year\").withColumnRenamed(\"Annual percentage change\",\n",
        "\"annual_percentage_change\")\n",
        "return df"
      ],
      "metadata": {
        "id": "yrVykN7AO5SZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "68sOqK0aSjG1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "zXL49OVfSjJX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import pyspark\n",
        "from pyspark.sql import SparkSession\n",
        "from pyspark.sql.functions import col, udf\n",
        "from pyspark.sql.types import StringType"
      ],
      "metadata": {
        "id": "MZ5GQABxSjL9"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import pyspark\n",
        "from pyspark.sql import SparkSession\n",
        "from pyspark.sql.functions import col, udf\n",
        "from pyspark.sql.types import StringType\n",
        "\n",
        "spark = SparkSession.builder.appName('SparkByExamples.com').getOrCreate()\n",
        "\n",
        "columns = [\"Seqno\",\"Name\"]\n",
        "data = [(\"1\", \"john jones\"),\n",
        "    (\"2\", \"tracey smith\"),\n",
        "    (\"3\", \"amy sanders\")]\n",
        "\n",
        "df = spark.createDataFrame(data=data,schema=columns)\n",
        "\n",
        "df.show(truncate=False)\n",
        "\n",
        "def convertCase(str):\n",
        "    resStr=\"\"\n",
        "    arr = str.split(\" \")\n",
        "    for x in arr:\n",
        "       resStr= resStr + x[0:1].upper() + x[1:len(x)] + \" \"\n",
        "    return resStr\n",
        "\n",
        "\"\"\" Converting function to UDF \"\"\"\n",
        "convertUDF = udf(lambda z: convertCase(z))\n",
        "\n",
        "df.select(col(\"Seqno\"), \\\n",
        "    convertUDF(col(\"Name\")).alias(\"Name\") ) \\\n",
        ".show(truncate=False)\n",
        "\n",
        "def upperCase(str):\n",
        "    return str.upper()\n",
        "\n",
        "upperCaseUDF = udf(lambda z:upperCase(z),StringType())\n",
        "\n",
        "df.withColumn(\"Cureated Name\", upperCaseUDF(col(\"Name\"))) \\\n",
        ".show(truncate=False)\n",
        "\n",
        "\"\"\" Using UDF on SQL \"\"\"\n",
        "spark.udf.register(\"convertUDF\", convertCase,StringType())\n",
        "df.createOrReplaceTempView(\"NAME_TABLE\")\n",
        "spark.sql(\"select Seqno, convertUDF(Name) as Name from NAME_TABLE\") \\\n",
        "     .show(truncate=False)\n",
        "\n",
        "spark.sql(\"select Seqno, convertUDF(Name) as Name from NAME_TABLE \" + \\\n",
        "          \"where Name is not null and convertUDF(Name) like '%John%'\") \\\n",
        "     .show(truncate=False)\n",
        "\n",
        "\"\"\" null check \"\"\"\n",
        "\n",
        "columns = [\"Seqno\",\"Name\"]\n",
        "data = [(\"1\", \"john jones\"),\n",
        "    (\"2\", \"tracey smith\"),\n",
        "    (\"3\", \"amy sanders\"),\n",
        "    ('4',None)]\n",
        "\n",
        "df2 = spark.createDataFrame(data=data,schema=columns)\n",
        "df2.show(truncate=False)\n",
        "df2.createOrReplaceTempView(\"NAME_TABLE2\")\n",
        "\n",
        "spark.udf.register(\"_nullsafeUDF\", lambda str: convertCase(str) if not str is None else \"\" , StringType())\n",
        "\n",
        "spark.sql(\"select _nullsafeUDF(Name) from NAME_TABLE2\") \\\n",
        "     .show(truncate=False)\n",
        "\n",
        "spark.sql(\"select Seqno, _nullsafeUDF(Name) as Name from NAME_TABLE2 \" + \\\n",
        "          \" where Name is not null and _nullsafeUDF(Name) like '%John%'\") \\\n",
        "     .show(truncate=False)\n"
      ],
      "metadata": {
        "id": "aLTAhlRXSjNv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "MDYr8YWlSjQY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.functions import *\n",
        "from pyspark.sql.types import *\n",
        "def get_english_name(species):\n",
        "  return species.split('(')[0].rstrip()\n",
        "def get_start_year(period):\n",
        "  start_year = period.split('-')[0]\n",
        "  start_year = start_year[1:]\n",
        "  syear = int(start_year)\n",
        "  return syear\n",
        "def get_trend(annual_percentage_change):\n",
        "  if annual_percentage_change <= -3.00:\n",
        "    return 'strong decline'\n",
        "  elif annual_percentage_change > -3.00 and annual_percentage_change <= -0.50:\n",
        "    return 'weak decline'\n",
        "  elif annual_percentage_change > -0.50 and annual_percentage_change < 0.50:\n",
        "    return 'no change'\n",
        "  elif annual_percentage_change >= 0.50 and annual_percentage_change <= 3.00:\n",
        "    return 'weak increase'\n",
        "  elif annual_percentage_change > 3.00:\n",
        "    return 'strong increase'\n"
      ],
      "metadata": {
        "id": "wvf6vu2uSjSF"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\" Converting function to UDF \"\"\"\n",
        "getNamesUDF = udf(lambda z: get_english_name(z))\n",
        "\n",
        "data.select(col(\"Category\"), \\\n",
        "    getNamesUDF(col(\"Species\")).alias(\"English_Name\") ) \\\n",
        ".show(truncate=False)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l-72lxGoUn7s",
        "outputId": "4a410f65-6974-435c-eff1-82066b4118d4"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----------------------+-------------+\n",
            "|Category               |English_Name |\n",
            "+-----------------------+-------------+\n",
            "|Farmland birds         |Greenfinch   |\n",
            "|Woodland birds         |Siskin       |\n",
            "|Seabirds               |European shag|\n",
            "|Water and wetland birds|Mute Swan    |\n",
            "|other                  |Collared Dove|\n",
            "+-----------------------+-------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "startYearUDF = udf(lambda z: get_start_year(z))\n",
        "\n",
        "data.select(col(\"Category\"), \\\n",
        "    startYearUDF(col(\"Period\")).alias(\"Start_Year\") ) \\\n",
        ".show(truncate=False)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7uX9irKtV_7u",
        "outputId": "01d59331-f35b-47a1-a78c-ff653ac38afc"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----------------------+----------+\n",
            "|Category               |Start_Year|\n",
            "+-----------------------+----------+\n",
            "|Farmland birds         |1970      |\n",
            "|Woodland birds         |1995      |\n",
            "|Seabirds               |1986      |\n",
            "|Water and wetland birds|1975      |\n",
            "|other                  |1970      |\n",
            "+-----------------------+----------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "getTrendUDF = udf(lambda z: get_trend(z))\n",
        "\n",
        "data.select(col(\"Category\"), \\\n",
        "    getTrendUDF(col(\"Annual_percentage_change\")).alias(\"Trend\") ) \\\n",
        ".show(truncate=False)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ud7Bh5ngV_-f",
        "outputId": "e0175d79-b15a-46fd-b45c-b56ebe690e2a"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----------------------+---------------+\n",
            "|Category               |Trend          |\n",
            "+-----------------------+---------------+\n",
            "|Farmland birds         |weak decline   |\n",
            "|Woodland birds         |weak increase  |\n",
            "|Seabirds               |weak decline   |\n",
            "|Water and wetland birds|weak increase  |\n",
            "|other                  |strong increase|\n",
            "+-----------------------+---------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#register UDFS\n",
        "spark.udf.register(\"getNamesUDF\", get_english_name,StringType())\n",
        "spark.udf.register(\"getTrendUDF\", get_trend,StringType())\n",
        "spark.udf.register(\"startYearUDF\", get_start_year,IntegerType())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iUV7BlLoZx7z",
        "outputId": "43997a7e-230f-45c0-a1b1-6b6293514c1d"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<function __main__.get_start_year(period)>"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\" Using UDF on SQL \"\"\"\n",
        "\n",
        "data.(\"NAME_TABLE\")\n",
        "spark.sql(\"select getNamesUDF(Species) as English_Name, startYearUDF(Period) as Start_Year, getTrendUDF(Annual_percentage_change) as Trend from NAME_TABLE\") \\\n",
        "     .show(truncate=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0MwjCy33ZyFe",
        "outputId": "a47c94a4-8270-4595-d849-01f3fd7028d8"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------------+----------+---------------+\n",
            "|English_Name |Start_Year|Trend          |\n",
            "+-------------+----------+---------------+\n",
            "|Greenfinch   |1970      |weak decline   |\n",
            "|Siskin       |1995      |weak increase  |\n",
            "|European shag|1986      |weak decline   |\n",
            "|Mute Swan    |1975      |weak increase  |\n",
            "|Collared Dove|1970      |strong increase|\n",
            "+-------------+----------+---------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "NAME_TABLE.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 165
        },
        "id": "4_Pk31uDgl0o",
        "outputId": "38cce63f-45a4-47a6-8bbb-c479b64b30e1"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-47-66d110670647>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mNAME_TABLE\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'NAME_TABLE' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "7h9ciFh9gl38"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\" Using UDF on SQL \"\"\"\n",
        "\n",
        "data.createOrReplaceTempView(\"NAME_TABLE\")\n",
        "spark.sql(\"select getNamesUDF(Species) as English_Name, startYearUDF(Period) as Start_Year, getTrendUDF(Annual_percentage_change) as Trend from NAME_TABLE\") \\\n",
        "     .show(truncate=False)"
      ],
      "metadata": {
        "id": "hOcmL_gdgl6Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "6DeIP0sIgl9U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "OjDpoDRygl_b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "h6bBn3KIgmCk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "B1ghaFyLgmGu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "xyaDObdpgmKA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Dk0XU-kxgmO_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "4LpE1J6bgmSu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ZCxxH3NAgmVe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "0QUbzmt-gmZL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "YsjcDGNIgmb2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 321
        },
        "id": "i5aVlUsGeKnd",
        "outputId": "254a9c18-ae31-4353-dbd4-01d1aac37b5c"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-45-7e5e4b234524>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mspark\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreateDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"NAME_TABLE\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mspark\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msql\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"select getNamesUDF(Species) as English_Name, startYearUDF(Period) as Start_Year, getTrendUDF(Annual_percentage_change) as Trend from NAME_TABLE\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m      \u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtruncate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pyspark/sql/dataframe.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   2975\u001b[0m         \"\"\"\n\u001b[1;32m   2976\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2977\u001b[0;31m             raise AttributeError(\n\u001b[0m\u001b[1;32m   2978\u001b[0m                 \u001b[0;34m\"'%s' object has no attribute '%s'\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2979\u001b[0m             )\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'DataFrame' object has no attribute 'spark'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "bMNIjwGKeKwx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "df.write.parquet('data/output/chargepoints-2017-analysis')"
      ],
      "metadata": {
        "id": "xshCrVIEa5OF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "cSB3utqBa5Rf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "E8tz8BrKa5Xh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "NdoKbRULbOv2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "CK13BAh2bO7q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\" null check \"\"\"\n",
        "\n",
        "columns = [\"Seqno\",\"Name\"]\n",
        "data = [(\"1\", \"john jones\"),\n",
        "    (\"2\", \"tracey smith\"),\n",
        "    (\"3\", \"amy sanders\"),\n",
        "    ('4',None)]\n",
        "\n",
        "df2 = spark.createDataFrame(data=data,schema=columns)\n",
        "df2.show(truncate=False)\n",
        "df2.createOrReplaceTempView(\"NAME_TABLE2\")\n",
        "\n",
        "spark.udf.register(\"_nullsafeUDF\", lambda str: convertCase(str) if not str is None else \"\" , StringType())\n",
        "\n",
        "spark.sql(\"select _nullsafeUDF(Name) from NAME_TABLE2\") \\\n",
        "     .show(truncate=False)\n",
        "\n",
        "spark.sql(\"select Seqno, _nullsafeUDF(Name) as Name from NAME_TABLE2 \" + \\\n",
        "          \" where Name is not null and _nullsafeUDF(Name) like '%John%'\") \\\n",
        "     .show(truncate=False)"
      ],
      "metadata": {
        "id": "V8GkuF03bO-w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "OwTeeKdsbPBC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\"\"\" Using UDF on SQL \"\"\"\n",
        "spark.udf.register(\"getNamesUDF\", get_english_name,StringType())\n",
        "data.createOrReplaceTempView(\"NAME_TABLE\")\n",
        "spark.sql(\"select Category, getNamesUDF(Species) as English_Name from NAME_TABLE\") \\\n",
        "     .show(truncate=False)\n",
        ""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S3q_uRJNWACF",
        "outputId": "0d7b7525-212a-4fc0-e75a-c08f24d8c110"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----------------------+-------------+\n",
            "|Category               |English_Name |\n",
            "+-----------------------+-------------+\n",
            "|Farmland birds         |Greenfinch   |\n",
            "|Woodland birds         |Siskin       |\n",
            "|Seabirds               |European shag|\n",
            "|Water and wetland birds|Mute Swan    |\n",
            "|other                  |Collared Dove|\n",
            "+-----------------------+-------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "C04_N-xRgfUm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\"\"\" Using UDF on SQL \"\"\"\n",
        "spark.udf.register(\"getNamesUDF\", get_english_name,StringType())\n",
        "data.createOrReplaceTempView(\"NAME_TABLE\")\n",
        "spark.sql(\"select Category, getNamesUDF(Species) as English_Name from NAME_TABLE\") \\\n",
        "     .show(truncate=False)\n",
        ""
      ],
      "metadata": {
        "id": "SWiz7eyegfYa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "kB-dHGiJgfdS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "FgI6GjQtgfhU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "CPuKhYpIgfk7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "zpEohqdmgfoJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "6wnIqkThgfp6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "HFLG6wlSgfsh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "7DTJ0ScUgfuH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "sEjf7b6lgfwy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "spark.sql(\"select Seqno, convertUDF(Name) as Name from NAME_TABLE \" + \\\n",
        "          \"where Name is not null and convertUDF(Name) like '%John%'\") \\\n",
        "     .show(truncate=False)"
      ],
      "metadata": {
        "id": "rrlzpgV0WAE5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def upperCase(str):\n",
        "    return str.upper()\n",
        "\n",
        "upperCaseUDF = udf(lambda z:upperCase(z),StringType())\n",
        "\n",
        "df.withColumn(\"Cureated Name\", upperCaseUDF(col(\"Name\"))) \\\n",
        ".show(truncate=False)\n"
      ],
      "metadata": {
        "id": "rbX-xO5aUn_J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "get_english_name = udf(get_english_name,StringType())\n",
        "get_start_year = udf(get_start_year,IntegerType())\n",
        "get_trend = udf(get_trend,StringType())"
      ],
      "metadata": {
        "id": "VBU2Q-IASjUA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9yaQruKESjWk",
        "outputId": "79eba885-f6ff-4914-8b9e-f415dd678af6"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------------+--------------------+-----------+------------------------+\n",
            "|             Species|            Category|     Period|Annual_percentage_change|\n",
            "+--------------------+--------------------+-----------+------------------------+\n",
            "|Greenfinch (Chlor...|      Farmland birds|(1970-2014)|                   -1.13|\n",
            "|Siskin (Carduelis...|      Woodland birds|(1995-2014)|                    2.26|\n",
            "|European shag (Ph...|            Seabirds|(1986-2014)|                   -2.31|\n",
            "|Mute Swan (Cygnus...|Water and wetland...|(1975-2014)|                    1.65|\n",
            "|Collared Dove (St...|               other|(1970-2014)|                     5.2|\n",
            "+--------------------+--------------------+-----------+------------------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#3. get_trend - this function should get the Annual percentage change column value and return the change trend category based on the following rules:\n",
        "#a. Annual percentage change less than -3.00 – return 'strong decline'\n",
        "#b. Annual percentage change between -3.00 and -0.50 (inclusive) – return 'weak decline'\n",
        "#c. Annual percentage change between -0.50 and 0.50 (exclusive) – return 'no change'\n",
        "#d. Annual percentage change between 0.50 and 3.00 (inclusive) – return 'weak increase'\n",
        "#e. Annual percentage change more than 3.00 – return 'strong increase'.\n",
        "#"
      ],
      "metadata": {
        "id": "BD_pv0YxXLZ3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "----------------------------------------------+-----------------------+-----------+------------------------+\n",
        "|Species                                       |Category               |Period     |Annual percentage change|\n",
        "+----------------------------------------------+-----------------------+-----------+------------------------+\n",
        "|Greenfinch (Chloris chloris)                  |Farmland birds         |(1970-2014)|-1.13                   |\n",
        "|Siskin (Carduelis spinus)                     |Woodland birds         |(1995-2014)|2.26                    |\n",
        "|European shag (Phalacrocorax artistotelis)    |Seabirds               |(1986-2014)|-2.31                   |\n",
        "|Mute Swan (Cygnus olor)                       |Water and wetland birds|(1975-2014)|1.65                    |\n",
        "|Collared Dove (Streptopelia decaocto)         |Other                  |(1970-2014)|5.2                     |\n",
        "+----------------------------------------------+-----------------------+-----------+------------------------+"
      ],
      "metadata": {
        "id": "LtGif19WXLwI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from os.path import abspath\n",
        "from pyspark.sql import SparkSession\n",
        "\n",
        "# warehouse_location points to the default location for managed databases and tables\n",
        "warehouse_location = abspath('spark-warehouse')\n",
        "\n",
        "# Create spark session with hive enabled\n",
        "spark = SparkSession \\\n",
        "    .builder \\\n",
        "    .appName(\"SparkByExamples.com\") \\\n",
        "    .config(\"spark.sql.warehouse.dir\", warehouse_location) \\\n",
        "    .config(\"spark.sql.catalogImplementation\", \"hive\") \\\n",
        "    .enableHiveSupport() \\\n",
        "    .getOrCreate()\n",
        "\n",
        "columns = [\"id\", \"name\",\"age\",\"gender\"]\n",
        "\n",
        "# Create DataFrame\n",
        "data = [(1, \"James\",30,\"M\"), (2, \"Ann\",40,\"F\"),\n",
        "    (3, \"Jeff\",41,\"M\"),(4, \"Jennifer\",20,\"F\")]\n",
        "sampleDF = spark.sparkContext.parallelize(data).toDF(columns)\n",
        "\n",
        "# Create database\n",
        "spark.sql(\"CREATE DATABASE IF NOT EXISTS emp\")\n",
        "\n",
        "# Create Hive Internal table\n",
        "sampleDF.write.mode('overwrite') \\\n",
        "          .saveAsTable(\"emp.employee\")\n",
        "\n",
        "# Spark read Hive table\n",
        "df = spark.read.table(\"emp.employee\")\n",
        "df.show()"
      ],
      "metadata": {
        "id": "hWo4NlgqfvOo"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}